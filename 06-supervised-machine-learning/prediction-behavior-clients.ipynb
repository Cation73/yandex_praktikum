{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отток клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сфера деятельности - банковская.\n",
    "\n",
    "Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. \n",
    "\n",
    "Метрики качества - *F1-мера, AUC ROC.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Изучим данные\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9091.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>4.997690</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.894723</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age       Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  9091.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800     4.997690   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806     2.894723   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000     0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000     2.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000     5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000     7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000    10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             9091 non-null float64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "row_number          10000 non-null int64\n",
      "customer_id         10000 non-null int64\n",
      "surname             10000 non-null object\n",
      "credit_score        10000 non-null int64\n",
      "geography           10000 non-null object\n",
      "gender              10000 non-null object\n",
      "age                 10000 non-null int64\n",
      "tenure              9091 non-null float64\n",
      "balance             10000 non-null float64\n",
      "num_of_products     10000 non-null int64\n",
      "has_cr_card         10000 non-null int64\n",
      "is_active_member    10000 non-null int64\n",
      "estimated_salary    10000 non-null float64\n",
      "exited              10000 non-null int64\n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# приведем все к нижнему регистру\n",
    "data.columns = map(str.lower, data.columns)\n",
    "data = data.rename(columns={'rownumber': 'row_number', \n",
    "                            'customerid': 'customer_id', \n",
    "                            'creditscore':'credit_score', \n",
    "                            'numofproducts': 'num_of_products', \n",
    "                            'hascrcard':'has_cr_card', \n",
    "                            'isactivemember':'is_active_member', \n",
    "                            'estimatedsalary':'estimated_salary'})\n",
    "def lower_object_string(df):\n",
    "    if df.dtype=='object':\n",
    "        df = df.str.lower()\n",
    "    return df\n",
    "data = data.apply(lambda x: lower_object_string(x))\n",
    "# проверим\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smith      32\n",
       "martin     29\n",
       "scott      29\n",
       "walker     28\n",
       "brown      26\n",
       "           ..\n",
       "wells       1\n",
       "zarate      1\n",
       "mauldon     1\n",
       "stanton     1\n",
       "lindon      1\n",
       "Name: surname, Length: 2931, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['surname'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      5457\n",
       "female    4543\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "france     5014\n",
       "germany    2509\n",
       "spain      2477\n",
       "Name: geography, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['geography'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tenure\n",
       "0.0     80135.307277\n",
       "1.0     77365.221712\n",
       "2.0     76502.413053\n",
       "3.0     78105.560356\n",
       "4.0     74133.600373\n",
       "5.0     76138.007217\n",
       "6.0     74970.085698\n",
       "7.0     75915.378086\n",
       "8.0     77994.797685\n",
       "9.0     77325.410351\n",
       "10.0    73580.495964\n",
       "Name: balance, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим, есть ли какая-нибудь взаимосвязь столбца с пропущеннными данными (количество недвижимости) по сравнению с другими\n",
    "data.groupby('tenure')['balance'].mean()\n",
    "# Явной зависимости нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tenure\n",
       "0.0     39.306283\n",
       "1.0     39.646008\n",
       "2.0     39.246316\n",
       "3.0     38.984914\n",
       "4.0     38.116384\n",
       "5.0     39.242718\n",
       "6.0     38.637911\n",
       "7.0     38.349189\n",
       "8.0     38.496249\n",
       "9.0     39.506803\n",
       "10.0    39.195067\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('tenure')['age'].mean()\n",
    "# тоже самое, явной зависимости не наблюдается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tenure\n",
       "0.0      99565.395157\n",
       "1.0     100635.368718\n",
       "2.0      99120.730168\n",
       "3.0      97351.648168\n",
       "4.0     100041.330836\n",
       "5.0     101239.472233\n",
       "6.0     100151.566924\n",
       "7.0     101842.455362\n",
       "8.0     100611.163290\n",
       "9.0      99592.441995\n",
       "10.0    102841.772040\n",
       "Name: estimated_salary, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('tenure')['estimated_salary'].mean()\n",
    "# аналогичная ситуация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tenure\n",
       "0.0     651.913613\n",
       "1.0     648.681723\n",
       "2.0     654.644211\n",
       "3.0     651.096983\n",
       "4.0     650.681356\n",
       "5.0     649.962244\n",
       "6.0     647.757094\n",
       "7.0     649.195676\n",
       "8.0     648.618435\n",
       "9.0     655.086168\n",
       "10.0    651.670404\n",
       "Name: credit_score, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('tenure')['credit_score'].mean()\n",
    "# нет явной зависимости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поэтому наилучшим вариантом будет заменить пропущенные данные медианами\n",
    "data['tenure'] = data['tenure'].fillna(data['tenure'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поменяем тип данных для balance, estimated_salary и tenure, так как удобнее будет работать с целочисленными данными\n",
    "data['balance'] = data['balance'].astype('int')\n",
    "data['estimated_salary'] = data['estimated_salary'].astype('int')\n",
    "data['tenure'] = data['tenure'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 12 columns):\n",
      "credit_score         10000 non-null int64\n",
      "age                  10000 non-null int64\n",
      "tenure               10000 non-null int64\n",
      "balance              10000 non-null int64\n",
      "num_of_products      10000 non-null int64\n",
      "has_cr_card          10000 non-null int64\n",
      "is_active_member     10000 non-null int64\n",
      "estimated_salary     10000 non-null int64\n",
      "exited               10000 non-null int64\n",
      "geography_germany    10000 non-null uint8\n",
      "geography_spain      10000 non-null uint8\n",
      "gender_male          10000 non-null uint8\n",
      "dtypes: int64(9), uint8(3)\n",
      "memory usage: 732.5 KB\n"
     ]
    }
   ],
   "source": [
    "# Применим прямое кодирование\n",
    "data_ohe = data.drop(['row_number', 'customer_id', 'surname'], axis=1)\n",
    "data_ohe = pd.get_dummies(data_ohe, drop_first=True)\n",
    "data_ohe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 2000, 2000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Разобьем исходные данные на обучающую (df_train), валидационную (df_val) и тестовую выборки (df_test) в соотношении 3:1:1\n",
    "data_train, data_test = train_test_split(data_ohe, test_size=0.2, random_state=12345)\n",
    "data_train, data_valid = train_test_split(data_train, test_size=0.25, random_state=12345)\n",
    "# Проверим получилось ли разделить данные в необходимом соотношении\n",
    "data_train.shape[0], data_test.shape[0], data_valid.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 11), (2000, 11), (6000, 11))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train = data_train.drop(['exited'], axis=1)\n",
    "target_train = data_train['exited']\n",
    "features_valid = data_valid.drop(['exited'], axis=1)\n",
    "target_valid = data_valid['exited']\n",
    "features_test = data_test.drop(['exited'], axis=1)\n",
    "target_test = data_test['exited']\n",
    "features_test.shape, features_valid.shape, features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Масштабируем признаки      \n",
    "numeric = ['credit_score', 'age', 'tenure', 'balance', 'num_of_products', 'estimated_salary']\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном этапе данные были приведены к нижнему регистру как индексы, так и названия колонок, были заменены пропуски в столбце tenure на заглушки, поменяли типы данных для столбцов balance, estimated_salary (нет необходимости видеть суммы до копеек) и tenure (количество недвижимости не может быть нецелочисленным значением)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Исследование задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим первую модель - решающее дерево."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score для Decision Tree на валидационной выборке: 0.5096693267584176\n",
      "AUC-ROC для Decision Tree на валидационной выборке: 0.7580816013696449\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state = 12345)\n",
    "parameters_dt = {'criterion': ['gini', 'entropy'], # критерий\n",
    "                 'max_depth':range(1, 50), # глубина дерева\n",
    "                 'min_samples_leaf': range(1, 20), # минимальное количесто объектов в листе\n",
    "                 'max_features':range(1, features_train.shape[1]+1)} # максимальное количество фич\n",
    "search_dt = RandomizedSearchCV(dt, parameters_dt, cv=5, n_jobs = -1, scoring = 'f1')\n",
    "search_dt.fit(features_train, target_train)\n",
    "best_dt = search_dt.best_estimator_\n",
    "f1_score_val_dt = cross_val_score(best_dt, features_valid, target_valid, scoring = 'f1', cv = 10, n_jobs = -1)   \n",
    "auc_roc_val_dt = cross_val_score(best_dt, features_valid, target_valid, scoring = 'roc_auc', cv = 10, n_jobs = -1)\n",
    "print('F1-score для Decision Tree на валидационной выборке:', sum(f1_score_val_dt)/len(f1_score_val_dt))\n",
    "print('AUC-ROC для Decision Tree на валидационной выборке:', sum(auc_roc_val_dt)/len(auc_roc_val_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вторая модель - случайный лес."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score для Random Forest на валидационной выборке: 0.5316937017557966\n",
      "AUC-ROC для Random Forest на валидационной выборке: 0.8293713170887085\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state = 12345)\n",
    "parameters_rf = {'n_estimators': range(1, 200, 10), # количество деревьев \n",
    "                 'criterion': ['gini', 'entropy'], # критерий\n",
    "                 'max_depth':range(1, 50, 1), # глубина дерева\n",
    "                 'min_samples_leaf': range(1, 10), # минимальное количесто объектов в листе\n",
    "                 'max_features': range(1, features_train.shape[1]+1)} # максимальное количество фич\n",
    "search_rf = RandomizedSearchCV(rf, parameters_rf, cv=5, n_jobs = -1, scoring = 'f1')\n",
    "search_rf.fit(features_train, target_train)\n",
    "best_rf = search_rf.best_estimator_\n",
    "f1_score_val_rf = cross_val_score(best_rf, features_valid, target_valid, scoring = 'f1', cv = 10, n_jobs = -1)   \n",
    "auc_roc_val_rf = cross_val_score(best_rf, features_valid, target_valid, scoring = 'roc_auc', cv = 10, n_jobs = -1)\n",
    "print('F1-score для Random Forest на валидационной выборке:', sum(f1_score_val_rf)/len(f1_score_val_rf))\n",
    "print('AUC-ROC для Random Forest на валидационной выборке:', sum(auc_roc_val_rf)/len(auc_roc_val_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Третья модель - логистическая регрессия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score для Logistic Regression (l1) на валидационной выборке: 0.3036598141922943\n",
      "AUC-ROC для Logistic Regression (l1) на валидационной выборке: 0.7660286271699316\n",
      "\n",
      "F1_score для Logistic Regression (l2) на валидационной выборке: 0.30417552985749013\n",
      "AUC-ROC для Logistic Regression (l2) на валидационной выборке: 0.7662704053193184\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state = 12345)\n",
    "parameters_lr_1 = {'C': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 5, 10, 20, 50], # обратная сила регуляризации\n",
    "                 'penalty':['l1'], # Регуляризация \n",
    "                 'solver':['liblinear', 'saga']} # функция потерь\n",
    "parameters_lr_2 = {'C': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 5, 10, 20, 50], # обратная сила регуляризации\n",
    "                 'penalty':['l2'], # Регуляризация \n",
    "                 'solver':['lbfgs', 'saga', 'sag', 'newton-cg']} # функция потерь\n",
    "\n",
    "search_lr_1 = RandomizedSearchCV(lr, parameters_lr_1, cv=5, n_jobs = -1, scoring = 'f1')\n",
    "search_lr_1.fit(features_train, target_train)\n",
    "best_lr_1 = search_lr_1.best_estimator_\n",
    "f1_score_val_lr_1 = cross_val_score(best_lr_1, features_valid, target_valid, scoring = 'f1', cv = 10, n_jobs = -1)   \n",
    "auc_roc_val_lr_1 = cross_val_score(best_lr_1, features_valid, target_valid, scoring = 'roc_auc', cv = 10, n_jobs = -1) \n",
    "\n",
    "\n",
    "search_lr_2 = RandomizedSearchCV(lr, parameters_lr_2, cv=5, n_jobs = -1, scoring = 'f1')\n",
    "search_lr_2.fit(features_train, target_train)\n",
    "best_lr_2 = search_lr_2.best_estimator_\n",
    "f1_score_val_lr_2 = cross_val_score(best_lr_2, features_valid, target_valid, scoring = 'f1', cv = 10, n_jobs = -1)   \n",
    "auc_roc_val_lr_2 = cross_val_score(best_lr_2, features_valid, target_valid, scoring = 'roc_auc', cv = 10, n_jobs = -1) \n",
    "print('F1-score для Logistic Regression (l1) на валидационной выборке:', sum(f1_score_val_lr_1)/len(f1_score_val_lr_1))\n",
    "print('AUC-ROC для Logistic Regression (l1) на валидационной выборке:', sum(auc_roc_val_lr_1)/len(auc_roc_val_lr_1))\n",
    "print()\n",
    "print('F1-score для Logistic Regression (l2) на валидационной выборке:', sum(f1_score_val_lr_2)/len(f1_score_val_lr_2))\n",
    "print('AUC-ROC для Logistic Regression (l2) на валидационной выборке:', sum(auc_roc_val_lr_2)/len(auc_roc_val_lr_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_non_balance</th>\n",
       "      <th>auc_roc_non_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.509669</td>\n",
       "      <td>0.758082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.531694</td>\n",
       "      <td>0.829371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>logistic_regression (l1)</td>\n",
       "      <td>0.303660</td>\n",
       "      <td>0.766029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>logistic_regression (l2)</td>\n",
       "      <td>0.304176</td>\n",
       "      <td>0.766270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  f1_non_balance  auc_roc_non_balance\n",
       "0             decision_tree        0.509669             0.758082\n",
       "1             random_forest        0.531694             0.829371\n",
       "2  logistic_regression (l1)        0.303660             0.766029\n",
       "3  logistic_regression (l2)        0.304176             0.766270"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_non_balance = [['decision_tree', \n",
    "                     sum(f1_score_val_dt)/len(f1_score_val_dt), sum(auc_roc_val_dt)/len(auc_roc_val_dt)], \n",
    "                    ['random_forest', \n",
    "                     sum(f1_score_val_rf)/len(f1_score_val_rf), sum(auc_roc_val_rf)/len(auc_roc_val_rf)], \n",
    "                    ['logistic_regression (l1)', \n",
    "                     sum(f1_score_val_lr_1)/len(f1_score_val_lr_1), sum(auc_roc_val_lr_1)/len(auc_roc_val_lr_1)],\n",
    "                    ['logistic_regression (l2)', \n",
    "                     sum(f1_score_val_lr_2)/len(f1_score_val_lr_2), sum(auc_roc_val_lr_2)/len(auc_roc_val_lr_2)]]\n",
    "columns_non_balance = ['model', 'f1_non_balance', 'auc_roc_non_balance']\n",
    "table_non_balance = pd.DataFrame(data = data_non_balance, columns = columns_non_balance)\n",
    "table_non_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul> Для трех типов моделей были определены гиперпараметры, необходимые для достижения максимально возможной F1 меры. Как видно из таблицы, наибольшим значением обладает модель случайного леса. Близким значением обладает модель решающего дерева, а логистическая регрессия показала наихудший результат, равный 0.3. Вероятно, такие результаты связаны с тем, что мы не учитываем дисбаланс классов. Стоит отметить, что необходимого результата мы пока что не достигли (все значения F1 меньше 0.59). </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Борьба с дисбалансом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первая модель - решающее дерево."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score для Decision Tree (balanced) на валидационной выборке: 0.5017278460678608\n",
      "AUC-ROC для Decision Tree (balanced) на валидационной выборке: 0.7649570492912885\n"
     ]
    }
   ],
   "source": [
    "dt_balanced = DecisionTreeClassifier(random_state = 12345, class_weight = 'balanced')\n",
    "search_dt_balanced = RandomizedSearchCV(dt_balanced, parameters_dt, cv=5, n_jobs = -1, scoring = 'f1')\n",
    "search_dt_balanced.fit(features_train, target_train)\n",
    "best_dt_balanced = search_dt_balanced.best_estimator_\n",
    "f1_score_val_dt_b = cross_val_score(best_dt_balanced, features_valid, target_valid, scoring = 'f1', cv = 10, n_jobs = -1)   \n",
    "auc_roc_val_dt_b = cross_val_score(best_dt_balanced, features_valid, target_valid, scoring = 'roc_auc', cv = 10, n_jobs = -1)\n",
    "print('F1-score для Decision Tree (balanced) на валидационной выборке:', sum(f1_score_val_dt_b)/len(f1_score_val_dt_b))\n",
    "print('AUC-ROC для Decision Tree (balanced) на валидационной выборке:', sum(auc_roc_val_dt_b)/len(auc_roc_val_dt_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использование downsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1219\n",
       "0    1219\n",
       "Name: exited, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Напишем функцию для реализации downsampling\n",
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    features_downsampled = pd.concat([features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    target_downsampled = pd.concat([target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "    features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled, random_state=12345)\n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "features_downsampled, target_downsampled = downsample(features_train, target_train, 0.255)\n",
    "target_downsampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score для Decision Tree (downsampled) на валидационной выборке: 0.4616144692864653\n",
      "AUC-ROC для Decision Tree (downsampled) на валидационной выборке: 0.7940283086478738\n"
     ]
    }
   ],
   "source": [
    "search_dt.fit(features_downsampled, target_downsampled)\n",
    "best_dt_ds = search_dt.best_estimator_\n",
    "f1_score_val_dt_ds = cross_val_score(best_dt_ds, features_valid, target_valid, scoring = 'f1', cv = 10, n_jobs = -1)   \n",
    "auc_roc_val_dt_ds = cross_val_score(best_dt_ds, features_valid, target_valid, scoring = 'roc_auc', cv = 10, n_jobs = -1)\n",
    "print('F1-score для Decision Tree (downsampled) на валидационной выборке:', sum(f1_score_val_dt_ds)/len(f1_score_val_dt_ds))\n",
    "print('AUC-ROC для Decision Tree (downsampled) на валидационной выборке:', sum(auc_roc_val_dt_ds)/len(auc_roc_val_dt_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем upsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4876\n",
       "0    4781\n",
       "Name: exited, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Напишем функцию для upsamling\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345)\n",
    "    \n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 4)\n",
    "target_upsampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score для Decision Tree (upsampled) на валидационной выборке: 0.4787685564467261\n",
      "AUC-ROC для Decision Tree (upsampled) на валидационной выборке: 0.747300326485109\n"
     ]
    }
   ],
   "source": [
    "search_dt.fit(features_upsampled, target_upsampled)\n",
    "best_dt_us = search_dt.best_estimator_\n",
    "f1_score_val_dt_us = cross_val_score(best_dt_us, features_valid, target_valid, scoring = 'f1', cv = 10, n_jobs = -1)   \n",
    "auc_roc_val_dt_us = cross_val_score(best_dt_us, features_valid, target_valid, scoring = 'roc_auc', cv = 10, n_jobs = -1)\n",
    "print('F1-score для Decision Tree (upsampled) на валидационной выборке:', sum(f1_score_val_dt_us)/len(f1_score_val_dt_us))\n",
    "print('AUC-ROC для Decision Tree (upsampled) на валидационной выборке:', sum(auc_roc_val_dt_us)/len(auc_roc_val_dt_us))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вторая модель - случайный лес."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score для Random Forest (balanced) на валидационной выборке: 0.5702640033470395\n",
      "AUC-ROC для Random Forest (balanced) на валидационной выборке: 0.8440260192705846\n"
     ]
    }
   ],
   "source": [
    "rf_balanced = RandomForestClassifier(random_state = 12345, class_weight = 'balanced')\n",
    "search_rf_balanced = RandomizedSearchCV(rf_balanced, parameters_rf, cv=5, n_jobs = -1, scoring = 'f1')\n",
    "search_rf_balanced.fit(features_train, target_train)\n",
    "best_rf_balanced = search_rf_balanced.best_estimator_\n",
    "f1_score_val_rf_b = cross_val_score(best_rf_balanced, features_valid, target_valid, scoring = 'f1', cv = 10, n_jobs = -1)   \n",
    "auc_roc_val_rf_b = cross_val_score(best_rf_balanced, features_valid, target_valid, scoring = 'roc_auc', cv = 10, n_jobs = -1)\n",
    "print('F1-score для Random Forest (balanced) на валидационной выборке:', sum(f1_score_val_rf_b)/len(f1_score_val_rf_b))\n",
    "print('AUC-ROC для Random Forest (balanced) на валидационной выборке:', sum(auc_roc_val_rf_b)/len(auc_roc_val_rf_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Методика downsampling для случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score для Random Forest (downsampled) на валидационной выборке: 0.5225081536156467\n",
      "AUC-ROC для Random Forest (downsampled) на валидационной выборке: 0.8431139512661252\n"
     ]
    }
   ],
   "source": [
    "search_rf.fit(features_downsampled, target_downsampled)\n",
    "best_rf_ds = search_rf.best_estimator_\n",
    "f1_score_val_rf_ds = cross_val_score(best_rf_ds, features_valid, target_valid, scoring = 'f1', cv = 10, n_jobs = -1)   \n",
    "auc_roc_val_rf_ds = cross_val_score(best_rf_ds, features_valid, target_valid, scoring = 'roc_auc', cv = 10, n_jobs = -1)\n",
    "print('F1-score для Random Forest (downsampled) на валидационной выборке:', sum(f1_score_val_rf_ds)/len(f1_score_val_rf_ds))\n",
    "print('AUC-ROC для Random Forest (downsampled) на валидационной выборке:', sum(auc_roc_val_rf_ds)/len(auc_roc_val_rf_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Методика upsampling для случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score для Random Forest (upsampled) на валидационной выборке: 0.5275176986445127\n",
      "AUC-ROC для Random Forest (upsampled) на валидационной выборке: 0.833615922121357\n"
     ]
    }
   ],
   "source": [
    "search_rf.fit(features_upsampled, target_upsampled)\n",
    "best_rf_us = search_rf.best_estimator_\n",
    "f1_score_val_rf_us = cross_val_score(best_rf_us, features_valid, target_valid, scoring = 'f1', cv = 10, n_jobs = -1)   \n",
    "auc_roc_val_rf_us = cross_val_score(best_rf_us, features_valid, target_valid, scoring = 'roc_auc', cv = 10, n_jobs = -1)\n",
    "print('F1-score для Random Forest (upsampled) на валидационной выборке:', sum(f1_score_val_rf_us)/len(f1_score_val_rf_us))\n",
    "print('AUC-ROC для Random Forest (upsampled) на валидационной выборке:', sum(auc_roc_val_rf_us)/len(auc_roc_val_rf_us))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Третья модель - логистическая регрессия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score для Logistic Regression (l1, balanced) на валидационной выборке: 0.47856300591640555\n",
      "AUC-ROC для Logistic Regression (l1, balanced) на валидационной выборке: 0.7695491917502788\n",
      "\n",
      "F1_score для Logistic Regression (l2, balanced) на валидационной выборке: 0.4801724574049092\n",
      "AUC-ROC для Logistic Regression (l2, balanced) на валидационной выборке: 0.7698713967192228\n"
     ]
    }
   ],
   "source": [
    "lr_balanced = LogisticRegression(random_state = 12345, class_weight = 'balanced')\n",
    "\n",
    "search_lr_1_balanced = RandomizedSearchCV(lr_balanced, parameters_lr_1, cv=5, n_jobs = -1, scoring = 'f1')\n",
    "search_lr_1_balanced.fit(features_train, target_train)\n",
    "best_lr_1_b = search_lr_1_balanced.best_estimator_\n",
    "f1_score_val_lr_1_b = cross_val_score(best_lr_1_b, features_valid, target_valid, scoring = 'f1', cv = 10, n_jobs = -1)   \n",
    "auc_roc_val_lr_1_b = cross_val_score(best_lr_1_b, features_valid, target_valid, scoring = 'roc_auc', cv = 10, n_jobs = -1) \n",
    "\n",
    "\n",
    "search_lr_2_balanced = RandomizedSearchCV(lr_balanced, parameters_lr_2, cv=5, n_jobs = -1, scoring = 'f1')\n",
    "search_lr_2_balanced.fit(features_train, target_train)\n",
    "best_lr_2_b = search_lr_2_balanced.best_estimator_\n",
    "f1_score_val_lr_2_b = cross_val_score(best_lr_2_b, features_valid, target_valid, scoring = 'f1', cv = 10, n_jobs = -1)   \n",
    "auc_roc_val_lr_2_b = cross_val_score(best_lr_2_b, features_valid, target_valid, scoring = 'roc_auc', cv = 10, n_jobs = -1) \n",
    "print('F1-score для Logistic Regression (l1, balanced) на валидационной выборке:', \n",
    "      sum(f1_score_val_lr_1_b)/len(f1_score_val_lr_1_b))\n",
    "print('AUC-ROC для Logistic Regression (l1, balanced) на валидационной выборке:', \n",
    "      sum(auc_roc_val_lr_1_b)/len(auc_roc_val_lr_1_b))\n",
    "print()\n",
    "print('F1-score для Logistic Regression (l2, balanced) на валидационной выборке:', \n",
    "      sum(f1_score_val_lr_2_b)/len(f1_score_val_lr_2_b))\n",
    "print('AUC-ROC для Logistic Regression (l2, balanced) на валидационной выборке:', \n",
    "      sum(auc_roc_val_lr_2_b)/len(auc_roc_val_lr_2_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Методика downsampling для логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score для Logistic Regression (l1, downsampled) на валидационной выборке: 0.2787158537929946\n",
      "AUC-ROC для Logistic Regression (l1, downsampled) на валидационной выборке: 0.7670606386367256\n",
      "\n",
      "F1_score для Logistic Regression (l2, downsampled) на валидационной выборке: 0.26380855996516095\n",
      "AUC-ROC для Logistic Regression (l2, downsampled) на валидационной выборке: 0.7685331063863673\n"
     ]
    }
   ],
   "source": [
    "search_lr_1.fit(features_downsampled, target_downsampled)\n",
    "best_lr_1_ds = search_lr_1.best_estimator_\n",
    "f1_score_val_lr_1_ds = cross_val_score(best_lr_1_ds, features_valid, target_valid, scoring = 'f1', cv = 10, n_jobs = -1)   \n",
    "auc_roc_val_lr_1_ds = cross_val_score(best_lr_1_ds, features_valid, target_valid, scoring = 'roc_auc', cv = 10, n_jobs = -1) \n",
    "\n",
    "\n",
    "search_lr_2.fit(features_downsampled, target_downsampled)\n",
    "best_lr_2_ds = search_lr_2.best_estimator_\n",
    "f1_score_val_lr_2_ds = cross_val_score(best_lr_2_ds, features_valid, target_valid, scoring = 'f1', cv = 10, n_jobs = -1)   \n",
    "auc_roc_val_lr_2_ds = cross_val_score(best_lr_2_ds, features_valid, target_valid, scoring = 'roc_auc', cv = 10, n_jobs = -1) \n",
    "\n",
    "print('F1-score для Logistic Regression (l1, downsampled) на валидационной выборке:', \n",
    "      sum(f1_score_val_lr_1_ds)/len(f1_score_val_lr_1_ds))\n",
    "print('AUC-ROC для Logistic Regression (l1, downsampled) на валидационной выборке:', \n",
    "      sum(auc_roc_val_lr_1_ds)/len(auc_roc_val_lr_1_ds))\n",
    "print()\n",
    "print('F1-score для Logistic Regression (l2, downsampled) на валидационной выборке:', \n",
    "      sum(f1_score_val_lr_2_ds)/len(f1_score_val_lr_2_ds))\n",
    "print('AUC-ROC для Logistic Regression (l2, downsampled) на валидационной выборке:', \n",
    "      sum(auc_roc_val_lr_2_ds)/len(auc_roc_val_lr_2_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Методика upsampling для логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score для Logistic Regression (l1, upsampled) на валидационной выборке: 0.22621713611226898\n",
      "AUC-ROC для Logistic Regression (l1, upsampled) на валидационной выборке: 0.7678013019589107\n",
      "\n",
      "F1_score для Logistic Regression (l2, upsampled) на валидационной выборке: 0.26380855996516095\n",
      "AUC-ROC для Logistic Regression (l2, upsampled) на валидационной выборке: 0.7685330068482242\n"
     ]
    }
   ],
   "source": [
    "search_lr_1.fit(features_upsampled, target_upsampled)\n",
    "best_lr_1_us = search_lr_1.best_estimator_\n",
    "f1_score_val_lr_1_us = cross_val_score(best_lr_1_us, features_valid, target_valid, scoring = 'f1', cv = 10, n_jobs = -1)   \n",
    "auc_roc_val_lr_1_us = cross_val_score(best_lr_1_us, features_valid, target_valid, scoring = 'roc_auc', cv = 10, n_jobs = -1) \n",
    "\n",
    "\n",
    "search_lr_2.fit(features_upsampled, target_upsampled)\n",
    "best_lr_2_us = search_lr_2.best_estimator_\n",
    "f1_score_val_lr_2_us = cross_val_score(best_lr_2_us, features_valid, target_valid, scoring = 'f1', cv = 10, n_jobs = -1)   \n",
    "auc_roc_val_lr_2_us = cross_val_score(best_lr_2_us, features_valid, target_valid, scoring = 'roc_auc', cv = 10, n_jobs = -1) \n",
    "\n",
    "print('F1-score для Logistic Regression (l1, upsampled) на валидационной выборке:', \n",
    "      sum(f1_score_val_lr_1_us)/len(f1_score_val_lr_1_us))\n",
    "print('AUC-ROC для Logistic Regression (l1, upsampled) на валидационной выборке:', \n",
    "      sum(auc_roc_val_lr_1_us)/len(auc_roc_val_lr_1_us))\n",
    "print()\n",
    "print('F1-score для Logistic Regression (l2, upsampled) на валидационной выборке:', \n",
    "      sum(f1_score_val_lr_2_us)/len(f1_score_val_lr_2_us))\n",
    "print('AUC-ROC для Logistic Regression (l2, upsampled) на валидационной выборке:', \n",
    "      sum(auc_roc_val_lr_2_us)/len(auc_roc_val_lr_2_us))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_non_balance</th>\n",
       "      <th>f1_balance</th>\n",
       "      <th>f1_upsample</th>\n",
       "      <th>f1_downsample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.509669</td>\n",
       "      <td>0.501728</td>\n",
       "      <td>0.478769</td>\n",
       "      <td>0.461614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.531694</td>\n",
       "      <td>0.570264</td>\n",
       "      <td>0.527518</td>\n",
       "      <td>0.522508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>logistic_regression (l1)</td>\n",
       "      <td>0.303660</td>\n",
       "      <td>0.478563</td>\n",
       "      <td>0.226217</td>\n",
       "      <td>0.278716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>logistic_regression (l2)</td>\n",
       "      <td>0.304176</td>\n",
       "      <td>0.480172</td>\n",
       "      <td>0.263809</td>\n",
       "      <td>0.263809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  f1_non_balance  f1_balance  f1_upsample  \\\n",
       "0             decision_tree        0.509669    0.501728     0.478769   \n",
       "1             random_forest        0.531694    0.570264     0.527518   \n",
       "2  logistic_regression (l1)        0.303660    0.478563     0.226217   \n",
       "3  logistic_regression (l2)        0.304176    0.480172     0.263809   \n",
       "\n",
       "   f1_downsample  \n",
       "0       0.461614  \n",
       "1       0.522508  \n",
       "2       0.278716  \n",
       "3       0.263809  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balance = [['decision_tree', sum(f1_score_val_dt)/len(f1_score_val_dt), \n",
    "               sum(f1_score_val_dt_b)/len(f1_score_val_dt_b), \n",
    "               sum(f1_score_val_dt_us)/len(f1_score_val_dt_us), \n",
    "               sum(f1_score_val_dt_ds)/len(f1_score_val_dt_ds)], \n",
    "              ['random_forest', sum(f1_score_val_rf)/len(f1_score_val_rf), \n",
    "               sum(f1_score_val_rf_b)/len(f1_score_val_rf_b), \n",
    "               sum(f1_score_val_rf_us)/len(f1_score_val_rf_us), \n",
    "               sum(f1_score_val_rf_ds)/len(f1_score_val_rf_ds)], \n",
    "              ['logistic_regression (l1)', sum(f1_score_val_lr_1)/len(f1_score_val_lr_1), \n",
    "               sum(f1_score_val_lr_1_b)/len(f1_score_val_lr_1_b), \n",
    "               sum(f1_score_val_lr_1_us)/len(f1_score_val_lr_1_us), \n",
    "               sum(f1_score_val_lr_1_ds)/len(f1_score_val_lr_1_ds)],\n",
    "              ['logistic_regression (l2)', sum(f1_score_val_lr_2)/len(f1_score_val_lr_2), \n",
    "               sum(f1_score_val_lr_2_b)/len(f1_score_val_lr_2_b), \n",
    "               sum(f1_score_val_lr_2_us)/len(f1_score_val_lr_2_us), \n",
    "               sum(f1_score_val_lr_2_ds)/len(f1_score_val_lr_2_ds)]]\n",
    "columns_balance = ['model', 'f1_non_balance', 'f1_balance', 'f1_upsample', 'f1_downsample']\n",
    "table_balance = pd.DataFrame(data = data_balance, columns = columns_balance)\n",
    "table_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul> Как видно из таблицы выше, учитывая дисбаланс класса, мы смогли достичь большего значения F1-меры. </ul>\n",
    "   <ul> Для модели решающего дерева эффективнее всего было учитывывать дисбаланс через настройку модели, а методики upsampling и downsampling лишь уменьшили F1-меру. </ul>\n",
    "   <ul> Для случайного леса наилучший результат показала модель с учетом дисбаланса через настройку модели и методики downsample. </ul>\n",
    "   <ul> Для логистической регрессии учет дисбаланса привел к увеличению F1-меры.</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Тестирование модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score для Random Forest (balanced) на тестовой выборке: 0.630686148753337\n",
      "AUC-ROC для Random Forest (balanced) на тестовой выборке: 0.8649864744436762\n"
     ]
    }
   ],
   "source": [
    "# Так как наилучший результат показала модель случайного леса с балансом классов, настроенном через параметры модели,\n",
    "# протестируем именно её\n",
    "f1_score_test = cross_val_score(best_rf_balanced, features_test, target_test, scoring = 'f1', cv = 10, n_jobs = -1)   \n",
    "auc_roc_test = cross_val_score(best_rf_balanced, features_test, target_test, scoring = 'roc_auc', cv = 10, n_jobs = -1)\n",
    "print('F1-score для Random Forest (balanced) на тестовой выборке:', sum(f1_score_test)/len(f1_score_test))\n",
    "print('AUC-ROC для Random Forest (balanced) на тестовой выборке:', sum(auc_roc_test)/len(auc_roc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul> В ходе работы были найдена наилучшая модель, которая на тестовых данных показала значения метрики F1 больше, чем 0.59. Таким образом, необходимая задача была выполнена. </ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
